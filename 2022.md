---
layout: page
title: Reproducible Research @ AGILE '22
keywords:
    - reproducible research
    - open science
    - reproducibility
    - software carpentry
    - data carpentry
    - skill building
---

The Reproducible AGILE team is happy to contribute to the AGILE conference 2022 by organising two activities:

1. **[Reproducibility review](#reproducibility-review)**
1. Workshop **[Replication in geospatial research](/2022-replication-workshop)**

------

## Reproducibility review

For the third time, a reproducibility review is be conducted with all accepted full papers based on the mandatory [reproducible paper guidelines](https://doi.org/10.17605/OSF.IO/CB7Z8).

**The reproducibility reviews are published on OSF at [https://osf.io/r5w79/](https://osf.io/r5w79/) üëà**.

### Report

Reproducible AGILE  community member [Alexander Kmoch](https://orcid.org/0000-0003-4386-4450) presented an overview on the reproducibility review process and its results on behalf of reproducibility committee chair Daniel N√ºst at the final day of the conference.
The slides are published at <https://doi.org/10.5281/zenodo.6625206>.

A more extensive written report is published in [the document about the reproducibility review process](https://docs.google.com/document/d/1JHCQV7GP3YkKwp0Nii3dt3p3Y45hU56Xz2cr-xJVz34/edit#) in the weeks after the conference.

### Review details

Find all details about the conference and the submission guidelines, including information about the reproducibility guidelines and review on the conference website: [https://agile-online.org/conference-2022](https://agile-online.org/conference-2022).

If you want to get a quick overview about previous reproducibility reviews, [take a look at the presentation by reproducibility committee chair Daniel N√ºst at the Munin conference]({{ site.baseurl }}/2020).
All non-rejected submissions, i.e., papers that are accepted or have minor revisions only, will be screened for reproducibility based on the information provided in the Data and Software Availability section.
<img style="float: right" width="100" src="{{ site.baseurl }}/public/images/badge/AGILE-reproducible-badge_square.png" />
The reproducibility review happens after the scientific review, because some papers are irreproducible for good reason (e.g., conceptual work) and are still published.
Successfully reproduced papers will receive the Reproducible AGILE badge, see the [2020 proceedings](https://agile-giss.copernicus.org/articles/1/index.html) for some examples.

Learn more about the process in the [review process and reports document](https://osf.io/7rjpe/).

### Reproducibility committee

‚ÄºÔ∏è We are looking for more reproducibility reviewers ‚ÄºÔ∏è

If you are interested to learn more about computational reproducibility and contribute to the cultural change in GIScience and in the AGILE community, please nominate yourself to become a reproducibility reviewer by [sending an email to Daniel](mailto:daniel.nuest@uni-muenster.de).
See below for more information.

- Daniel N√ºst, _Chair_ (University of M√ºnster, Germany)
- Carlos Granell (Universitat of Jaume I, Spain)
- Eftychia Koukouraki (University of M√ºnster, Germany)
- Eleni Tomai (Cartography Laboratory, National Technical University of Athens, Greece)
- Frank Ostermann (University of Twente, The Netherlands)
- Jakub Krukar  (University of M√ºnster, Germany)
- Philipp Friese (Technical University of Munich, Germany)
- R√©my Decoupes (INRAE, UMR TETIS, Universit√© de Montpellier, France)

#### _What is expected from reproducibility reviewers?_

1. An **interest** to learn more about computational reproducibility.
   A good starting point are the [AGILE Reproducible Paper Guidelines](https://doi.org/10.17605/OSF.IO/CB7Z8), which you can familiarise yourself with.
1. Any **skills** with different software, tools, or programming languages are welcome, but not strictly necessary.
   We expect authors to provide good enough instructions for anyone to reproduce their work, so previous skills are really just important to ensure a time effective reproducibility review. Note that you can always reach out to fellow reproducibility reviewers for advice and help, and most importantly, the authors. A reproduction can be _collaborative_ endavour for author and reproducibility reviewer.
1. Some **time** in April/May 2022 (see conference schedule). The reproducibility reviews will be conducted after notification of full paper acceptance and must be completed before camera-ready papers are due so that the reference to the reproducibility report can be added.
   Based on previous years, a reproducibility review (executing the workflow & writing a report) takes between 2-4 hours, not counting the actual computations. This time is likely to be spread out across a couple of weeks as communications with authors take place and is comparable to the effort of a scientific review.

You can find a more elaborate description of the tasks in the [_Reproducibility Reviewer Guidelines_](https://doi.org/10.17605/OSF.IO/CB7Z8).

#### _How do I become a reproducibility reviewer?_

1. Register on the [AGILE Discourse server](https://discourse.agile-online.org/).
2. Send an [email to Daniel](mailto:daniel.nuest@uni-muenster.de) with a few words about why you want to join and your user name for the AGILE Discourse server, your email for accessing non-public Google Docs, and a link to your profile on [OSF](https://osf.io/).
3. Daniel will send you a short welcome message and invite you to the internal reproducibility reviewer discussion forum, where you can post your [interests and skills](https://discourse.agile-online.org/t/reproducibility-reviewer-skills/45/4), so that you can be matched to a submission when the reproductions start.
