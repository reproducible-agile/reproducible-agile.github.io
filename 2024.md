---
layout: page
title: Reproducible Research @ AGILE '24
keywords:
    - reproducible research
    - open science
    - reproducibility
    - software carpentry
    - data carpentry
    - skill building
---

The Reproducible AGILE team is happy to contribute to the AGILE conference 2024 by organising the reproducibility review, continueing an exemplary practice in Open Scholarship from the previous years.
For the fifth time, a reproducibility review is conducted with all accepted full papers based on the mandatory [reproducible paper guidelines](https://doi.org/10.17605/OSF.IO/CB7Z8).

<!--

**The reproducibility reviews are published on OSF at üëâ <https://osf.io/> üëà**.

## Report

Reproducibility committee chair Carlos presented an overview on the reproducibility review process and its results at the final day of the conference.
The slides are published at <https://osf.io/XXX>.

A more extensive written report is published in [the document about the reproducibility review process](https://docs.google.com/document/d/1JHCQV7GP3YkKwp0Nii3dt3p3Y45hU56Xz2cr-xJVz34/edit#).

-->

## Review details

Find all details about the conference and the submission guidelines, including information about the reproducibility guidelines and review on the conference website: <https://agile-online.org/conference-2024>.

If you want to get a quick overview about previous reproducibility reviews, [take a look at the presentation by reproducibility committee chair Daniel N√ºst at the Munin conference]({{ site.baseurl }}/2020).
In short, all non-rejected full paper submissions, i.e., papers that are accepted or have minor revisions only, will be screened for reproducibility based on the information provided in the Data and Software Availability section.

<img style="float: right" width="100" src="{{ site.baseurl }}/public/images/badge/AGILE-reproducible-badge_square.png" />

The reproducibility review happens after the scientific review, because some papers are irreproducible for good reason (e.g., conceptual work) and are still valuable scientific contributions.
Successfully reproduced papers will receive the Reproducible AGILE badge, see the [2020 proceedings](https://agile-giss.copernicus.org/articles/1/index.html) for some examples.

Learn more about the process in the [review process and reports document](https://osf.io/7rjpe/).

## Reproducibility committee

‚ÄºÔ∏è We are looking for more reproducibility reviewers ‚ÄºÔ∏è

If you are interested to learn more about computational reproducibility and contribute to the cultural change in GIScience and in the AGILE community, please nominate yourself to become a reproducibility reviewer by [sending an email to Carlos](mailto:carlos.granell@uji.es).
See below for more information.

- Carlos Granell, _Co-Chair_ (Universitat of Jaume I, Spain), carlos.granell@uji.es
- Frank Ostermann, _Co-Chair_ (University of Twente, the Netherlands), f.o.ostermann@utwente.nl
- Eftychia Koukouraki (University of M√ºnster, Germany)
- R√©my Decoupes (INRAE / UMR TETIS, Montpellier, France)
- Henrikki Tenkanen (Aalto University, Finland)
- Alexander Kmoch (University of Tartu, Estonia)


### _What is expected from reproducibility reviewers?_

1. An **interest** to learn more about computational reproducibility.
   A good starting point are the [AGILE Reproducible Paper Guidelines](https://doi.org/10.17605/OSF.IO/CB7Z8), which you can familiarise yourself with.
1. Any **skills** with different software, tools, or programming languages are welcome, but not strictly necessary.
   We expect authors to provide good enough instructions for anyone to reproduce their work, so previous skills are really just important to ensure a time effective reproducibility review. Note that you can always reach out to fellow reproducibility reviewers for advice and help, and most importantly, the authors. A reproduction can be _collaborative_ endavour for author and reproducibility reviewer.
1. Some **time** in April/May 2022 (see conference schedule). The reproducibility reviews will be conducted after notification of full paper acceptance and must be completed before camera-ready papers are due so that the reference to the reproducibility report can be added.
   Based on previous years, a reproducibility review (executing the workflow & writing a report) takes between 2-4 hours, not counting the actual computations. This time is likely to be spread out across a couple of weeks as communications with authors take place and is comparable to the effort of a scientific review.

You can find a more elaborate description of the tasks in the [_Reproducibility Reviewer Guidelines_](https://doi.org/10.17605/OSF.IO/CB7Z8).

### _How do I become a reproducibility reviewer?_

1. Register on the [AGILE Discourse server](https://discourse.agile-online.org/).
2. Send an [email to Carlos](mailto:carlos.granell@uji.es) with a few words about why you want to join and your user name for the AGILE Discourse server, your email for accessing non-public Google Docs, and a link to your profile on [OSF](https://osf.io/).
3. Carlos will send you a short welcome message and invite you to the internal reproducibility review coordination forum.
