---
layout: page
title: Reproducible Research @ AGILE '21
keywords:
    - reproducible research
    - open science
    - reproducibility
    - software carpentry
    - data carpentry
    - skill building
---

## Reproducibility review

The AGILE conference 2021 is be a fully virtual conference.
For the second time, a reproducibility review is be conducted with all (tentatively) accepted full papers.
For the first time, the [reproducibility guidelines](https://doi.org/10.17605/OSF.IO/CB7Z8) are _mandatory_.

The reproducibility reviews are published on OSF at [https://osf.io/h64sd/](https://osf.io/h64sd/).

## Report

Reproducibility committee chair Daniel Nüst reported on the progress of the initiative and the results of the 2021 reproducibility review in a decidated conference session on Friday, June 11th, 2021.
The slides are available at [https://doi.org/10.5281/zenodo.4926269](https://doi.org/10.5281/zenodo.4926269).

9 papers of 15 accepted manuscripts were successfully (partially) reproduced.
This corresponds to 60% percent of accepted papers.

[![Overview of all slides of the report talk]({{ site.baseurl }}/public/images/2021-talk-overview.png)](https://doi.org/10.5281/zenodo.4926269)

## Review details

Find all details about the conference and the submission guidelines, including information about the reproducibility guidelines and review on the conference website: [https://agile-online.org/conference-2021](https://agile-online.org/conference-2021).

If you want to get a quick overview about last year's reproducibility review, [take a look at the presentation by reproducibility committee chair Daniel Nüst at the Munin conference]({{ site.baseurl }}/2020).
All non-rejected submissions, i.e., papers that are accepted or have minor revisions only, will be screened for reproducibility based on the information provided in the Data and Software Availability section.
<img style="float: right" width="100" src="{{ site.baseurl }}/public/images/badge/AGILE-reproducible-badge_square.png" />
The reproducibility review happens after the scientific review, because irreproducible papers will still be published.
Successfully reproduced papers will receive the Reproducible AGILE badge, see the [2020 proceedings](https://agile-giss.copernicus.org/articles/1/index.html) for some examples.

Learn more about the process in the [review process and reports document](https://osf.io/7rjpe/).

## Reproducibility committee

{% comment %}
‼️ We are looking for more reproducibility reviewers ‼️

If you are interested to learn more about computational reproducibility and contribute to the cultural change in GIScience and in the AGILE community, please nominate yourself to become a reproducibility reviewer by [sending an email to Daniel](mailto:daniel.nuest@uni-muenster.de).
See below for more information.
{% endcomment %}

- Daniel Nüst, Chair (University of Münster, Germany)
- Frank Ostermann (University of Twente, The Netherlands)
- Carlos Granell (Universitat of Jaume I, Spain)
- Alexander Kmoch (University of Tartu, Estonia)
- Philipp Friese (Technical University of Munich, Germany)
- Anita Graser ( Austrian Institute of Technology, Austria)
- Jakub Krukar  (University of Münster, Germany)

A description of the reproducibility reviewers' tasks is in the [_Reproducibility Reviewer Guidelines_](https://doi.org/10.17605/OSF.IO/CB7Z8).

{% comment %}
### _What is expected from reproducibility reviewers?_

1. An **interest** to learn more about computational reproducibility.
   A good starting point are the [AGILE Reproducible Paper Guidelines](https://doi.org/10.17605/OSF.IO/CB7Z8), which you can familiarise yourself with.
1. Any **skills** with different software, tools, or programming languages are welcome, but not strictly necessary.
   We expect authors to provide good enough instructions for anyone to reproduce their work, so previous skills are really just important to ensure a time effective reproducibility review. Note that you can always reach out to fellow reproducibility reviewers for advice and help, and most importantly, the authors. A reproduction can be _collaborative_ endavour for author and reproducibility reviewer.
1. Some **time** in April 2021 (see [conference schedule](https://agile-online.org/conference-2021/important-dates-2021)). The reproducibility reviews will be conducted after notification of full paper acceptance (April 5) and must be completed before camera-ready papers are due (May 3) so that the reference to the reproducibility report can be added.
   Based on previous years, a reproducibility review (executing the workflow & writing a report) takes between 2-4 hours, not counting the actual computations. This time is likely to be spread out across a couple of weeks as communications with authors take place and is comparable to the effort of a scientific review.

You can find a more elaborate description of the tasks in the [_Reproducibility Reviewer Guidelines_](https://doi.org/10.17605/OSF.IO/CB7Z8).

### _How do I become a reproducibility reviewer?_

1. Register on the [AGILE Discourse server](https://discourse.agile-online.org/).
2. Send an [email to Daniel](mailto:daniel.nuest@uni-muenster.de) with your Discourse user name and a few words about why you want to join.
3. Daniel will send you a short welcome message and invite you to the internal reproducibility reviewer discussion forum, where you can post your [interests and skills](https://discourse.agile-online.org/t/reproducibility-reviewer-skills/45/4), so that you can be matched to a submission when the reproductions start.
{% endcomment %}
